# üëã Profile

Hi, I'm Siru, currently pursuing an **MPhil** degree in Data Science and Analytics at the **[HKUST (Guangzhou)](http://dsa.hkust-gz.edu.cn/)**, under the guidance of [Prof. Yuxuan Liang](https://yuxuanliang.com/) and [Prof. Yangqiu Song](https://www.cse.ust.hk/~yqsong/). My research primarily focuses on **Multi-modal** and **Data Mining**, specifically in Visual-Language Understanding, Editing, Generation, and Consistency Verification. I also explore innovative applications within Urban Computing.

Concurrently, I am a **Research Intern** at **XPENG** Autonomous Driving Center, where I conduct research related to **Visual Multi-modal** and contribute to the development of the **XNGP** (Navigation Guided Pilot), under the mentorship of [Dr. Cheng Lu](https://www.linkedin.com/in/cheng-lu-5b24a739). 

Previously, I worked as a full-time **Software Engineer** at **Tencent** PCG Tech-Center from 2022 to 2023. During my time there, I focused on **Cloud Native Infrastructure**, enhancing QQ‚Äôs performance, and developing tools such as CodeSpaces and Workflow Engine. I earned my Bachelor's degree in 2022 from **[HFUT](https://ci.hfut.edu.cn/)**, School of Computer and Information.

**More**:

+ üéì [LinkedIn](https://linkedin.com/in/siruzhong)
+ üìÆ [Google Scholar](https://scholar.google.co.uk/citations?user=3KMb5mUAAAAJ)
+ üëâ [CSDN](https://bareth.blog.csdn.net/)
+ üìß siruzhong@outlook.com


# üìñ Education

<ul>
  <li>
    2023 - 2025, M.Phil in Data Science and Analytics, <strong>Hong Kong University of Science and Technology</strong>
    <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-06-29-140657.png" style="width: 9em; vertical-align: middle;"><br>
  </li>
  <li>
    2018 - 2022, B.Eng in School of Computer and Information, <strong>Hefei University of Technology</strong>
    <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-02-27-172149.png" style="width: 8em; vertical-align: middle;">
  </li>
</ul>

# üíª Experience

<ul>
  <li>
   <strong>Research Intern ‚Äî Autonomous Driving Center</strong>, <em>XPeng Motors</em>, 2024.05 - Present.
    <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-05-24-025517.png" style="width: 7em;"><br>
    - Conducted research on Visual Multi-modal within the autonomous driving visual imaging team.<br>
    - Integrating the findings with the XGNP intelligent driving system to achieve innovative enhancements.
  </li>
  
  <li>
   <strong>Research Assistant ‚Äî CityMind Lab</strong>, <em>HKUST-GZ</em>, 2023.05 - 2023.08.
    <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-06-29-150454.png" style="width: 7em;"><br>
    - Contributed to two papers on spatio-temporal data prediction and interpolation, accepted by IJCAI-24.<br>
    - Completed multi-modal spatio-temporal data crawling and laboratory website construction.
  </li>
  
  <li>
   <strong>Software Engineer ‚Äî PCG CloudDev Center</strong>, <em>Tencent</em>, 2022.07 - 2023.05.
    <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-05-07-175529.png" style="width: 5em;"><br>
    - Focus on cloud-native infrastructure, develop event orchestration engine & cloud shared code development platform.<br>
    - Awarded with Tencent Excellent Newcomer & CodeWorld Project Silver Team & iCode Certification.
  </li>

  <li>
   <strong>Software Intern ‚Äî PCG Tech Center</strong>, <em>Tencent</em>, 2021.06 - 2021.09.
    <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-05-07-175529.png" style="width: 5em;"><br>
    - Improved the QQ publishing system, reducing online bugs by 30%.<br>
    - Received "A" rating in summer internship assessment & Earned a full-time SP Offer.
  </li>
  
</ul>

# üìù Publications
## Multi-modal
<table>
  <tr>
    <td width="30%">
      <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-04-23-033802.png" alt="UrbanCross" style="max-width:100%;" />
    </td>
    <td width="70%">
      <strong>Enhancing Satellite Image-Text Retrieval with Cross-Domain Adaptation</strong><br> 
      <ins><b>Siru Zhong</b></ins>, Xixuan Hao, Yibo Yan, Ying Zhang, Yangqiu Song, Yuxuan Liang<br> 
      <li><i>First-ever cross-domain framework that integrates the power of LMM and SAM into satellite image-text retrieval.</i>[<a href="https://arxiv.org/pdf/2404.14241.pdf">Arxiv</a>]</li>
      Under Review
    </td>
  </tr>
  <tr>
    <td width="30%">
      <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-01-24-160852.png" alt="UrbanCLIP" style="max-width:100%;" />
    </td>
    <td width="70%">
      <strong>Learning Text-enhanced Urban Region Profiling with Contrastive Language-Image Pretraining from the Web</strong><br> 
      Yibo Yan, Haomin Wen, <ins><b>Siru Zhong</b></ins>, Wei Chen, Haodong Chen, Qingsong Wen, Roger Zimmermann, Yuxuan Liang<br> 
      <li><i>First-ever LLM-enhanced framework that integrates the knowledge of textual modality into urban imagery profiling.</i>[<a href="https://arxiv.org/pdf/2310.18340.pdf">Link</a>]</li>
      The International World Wide Web Conference 2024, Singapore (WWW'24)
    </td>
  </tr>
  <tr>
    <td width="30%">
      <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-02-27-170045.png" alt="UrbanVLP" style="max-width:100%;" />
    </td>
    <td width="70%">
      <strong>A Multi-Granularity Vision-Language Pre-Trained Model for Urban Indicator Prediction</strong><br> 
      Xixuan Hao, Wei Chen, Yibo Yan, <ins><b>Siru Zhong</b></ins>, Kun Wang, Qingsong Wen, Yuxuan Liang<br>
      <li><i>First urban region representation learning framework that explores multi-granularity cross-modal alignment.</i>[<a href="https://arxiv.org/pdf/2403.16831.pdf">Arxiv</a>]</li>
      Under Review
    </td>
  </tr>
</table>

## Data Mining
<table>
  <tr>
    <td width="30%">
      <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-06-03-142808.png" alt="STFNN" style="max-width:100%;" />
    </td>
    <td width="70%">
      <strong>Predicting Parking Availability in Singapore with Cross-Domain Data: A New Dataset and A Data-Driven Approach</strong><br> 
      Huaiwu Zhang, Yutong Xia, <ins><b>Siru Zhong</b></ins>, Kun Wang, Zekun Tong, Qingsong Wen, Roger Zimmermann, Yuxuan Liang<br>
      <li><i>A novel deep-learning model for real-time parking availability in Singapore, analyzing external factors, introducing a new dataset, and improving prediction accuracy.</i>[<a href="https://arxiv.org/pdf/2405.18910">Link</a>]</li>
      The International Joint Conference on Artificial Intelligence 2024, Korea (IJCAI'24)
    </td>
  </tr>
  <tr>
    <td width="30%">
      <img src="https://siruzhong-1305674339.cos.ap-hongkong.myqcloud.com/2024-03-14-104146.png" alt="STFNN" style="max-width:100%;" />
    </td>
    <td width="70%">
      <strong>Spatio-Temporal Field Neural Networks for Air Quality Inference</strong><br> 
      Yutong Feng, Qiongyan Wang, Yutong Xia, Junlin Huang, <ins><b>Siru Zhong</b></ins>, Kun Wang, Shifen Cheng, Yuxuan Liang<br>
      <li><i>A pioneering Spatio-Temporal Field Neural Network model integrates two distinct perspectives on space and time to perform air quality inference.</i>[<a href="https://arxiv.org/pdf/2403.02354.pdf">Link</a>]</li>
      The International Joint Conference on Artificial Intelligence 2024, Korea (IJCAI'24)
    </td>
  </tr>
</table>


# üèÜ Awards
- 2023: Best Project Award in Data Science Computing (DSAA 5021) at HKUST(GZ)
- 2023: Outstanding Students of the Red Bird Challenge Camp at HKUST(GZ)
- 2022: Tencent iCode Certification
- 2022: Silver Award in Tencent Code World Program (2/12)
- 2022: Outstanding Student in Tencent Graduates Training (8/100)
- 2022: Outstanding Undergraduate Graduation Project at HFUT (%2)
- 2021: Third Prize in the National English Competition for College Students
- 2020: First Prize in the CSDN ‚ÄúGEEK+‚Äù Technical Original Blogger Contest
- 2020: Second Prize for the HFUT Robot Competition 2D Project Team

<!-- # GitHub stats
[![Siru's GitHub stats](https://github-readme-stats.vercel.app/api?username=siruzhong)](https://github.com/anuraghazra/github-readme-stats) -->
